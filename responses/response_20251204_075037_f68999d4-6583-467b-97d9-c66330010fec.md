# Agent Response - parallel_sectioning

**Session ID**: f68999d4-6583-467b-97d9-c66330010fec
**Processing Time**: 118.81 seconds

## Final Response

Here is a comprehensive technical architecture for the EcoFitAR Sustainable Commerce Platform, synthesizing expert perspectives on frontend, backend, data management, AR, and AI services.

---

### **EcoFitAR: Comprehensive Technical Architecture**

This document outlines the complete technical architecture for the EcoFitAR platform. It integrates a Next.js App Router frontend with a serverless Google Cloud backend, leveraging Firebase Firestore, Cloud Storage, and Cloud Functions to power the platform's core features, including AR virtual try-on and Gemini-powered AI services.

### 1. Overall System Architecture

EcoFitAR is designed as a modern, scalable web application. The architecture separates concerns into three primary layers that work in concert:

1.  **Frontend (Next.js):** A performant, mobile-first single-page application built with the Next.js App Router. It uses a hybrid of Server Components for fast initial loads and SEO, and Client Components for rich interactivity.
2.  **Backend & Data (Firebase):** A serverless backend using Firebase services. **Firestore** acts as the NoSQL database for all application data, **Cloud Storage** hosts all media assets like product images and AR overlays, and **Firebase Authentication** manages user identity.
3.  **AI Services (Google Cloud Functions & Gemini):** A secure backend-for-frontend (BFF) layer built with Cloud Functions. These serverless functions act as a secure proxy to the **Google Gemini API**, encapsulating all prompt engineering and protecting sensitive API keys from the client.



---

### 2. Frontend Architecture: Next.js App Router

The frontend is built to be modular and performant, leveraging the latest features of the Next.js App Router.

#### 2.1. Directory Structure

The project follows the standard `app` directory structure, using route groups `(main)` and `(immersive)` to apply different layouts without affecting the URL.

```plaintext
/app
├── (main)                                # Route group for views with the main Navbar
│   ├── layout.tsx                        # Main layout with Navbar
│   ├── page.tsx                          # FEED view (/)
│   └── product
│       └── [id]                          # Dynamic route for a single product
│           ├── page.tsx                  # PRODUCT_DETAILS view (/product/[id])
│           └── stylist
│               └── page.tsx              # STYLIST_CHAT view (/product/[id]/stylist)
│
├── (immersive)                           # Route group for full-screen, no-nav views
│   └── product
│       └── [id]
│           └── try-on
│               └── page.tsx              # AR_TRY_ON view (/product/[id]/try-on)
│
├── api                                   # API Routes (used if deploying on Vercel, otherwise Cloud Functions are preferred)
├── components                            # Reusable UI components
│   ├── ar/ARView.tsx                     # (Client Component)
│   ├── chat/GeminiStylist.tsx            # (Client Component)
│   ├── layout/Navbar.tsx                 # (Client Component)
│   ├── product/ProductCard.tsx           # (Server Component)
│   ├── product/SustainabilityTracker.tsx # (Server Component)
│   └── ui/                               # Generic UI primitives (buttons, sliders)
│
└── lib                                   # Helpers, Firebase config, data fetching
    ├── firebase.ts                       # Firebase client SDK initialization
    └── store.ts                          # Zustand store for global client state
```

#### 2.2. Component & Routing Strategy

The application's "View States" are mapped directly to routes, with a clear distinction between Server and Client Components.

*   **FEED (`/`):** A **Server Component** (`app/(main)/page.tsx`) that fetches product data from Firestore on the server for a fast, SEO-friendly initial load. It renders `<ProductCard>` Server Components.
*   **PRODUCT\_DETAILS (`/product/[id]`):** An `async` **Server Component** that fetches a single product's data. It renders static information server-side (like `<SustainabilityTracker>`) and includes interactive Client Components for features like the AI analysis.
*   **STYLIST\_CHAT (`/product/[id]/stylist`):** A page that hosts the `<GeminiStylist>` **Client Component**. It fetches initial product context on the server to pass as props.
*   **AR\_TRY\_ON (`/product/[id]/try-on`):** Placed in the `(immersive)` route group, this page renders the `<ARView>` **Client Component** without the main `Navbar` for a full-screen experience.

#### 2.3. State Management

A hybrid state management strategy ensures efficiency and simplicity:

1.  **URL as State:** The Next.js router is the primary source of truth for the current view and selected product, making the application's state shareable and resilient.
2.  **Component-Local State (`useState`, `useReducer`):** Used for state that is confined to a single component, such as the AR garment's transformations in `ARView.tsx` or the message history in `GeminiStylist.tsx`.
3.  **Shared Client State (Zustand):** A lightweight library like **Zustand** is used for minimal global state that needs to be shared across client components, such as the user's "Impact Stats" (e.g., CO2 saved), which might be displayed in both the Navbar and the main Feed.

---

### 3. Backend and Data Architecture: Firebase Platform

The backend is entirely serverless, leveraging the Firebase suite for scalability and ease of maintenance.

#### 3.1. Firestore NoSQL Database

Firestore stores all application data in a flexible collection-document model.

*   **`products` Collection:** Contains the entire curated product catalog. Each document represents one product.
    ```typescript
    // /products/{productId}
    interface Product {
      id: string;
      name: string;
      brand: string;
      price: number;
      image: string; // URL to Cloud Storage
      overlayImage: string; // URL to AR overlay in Cloud Storage
      sustainabilityScore: number; // 0-100
      carbonFootprint: string; // "5.2 kg CO2e"
      materials: string[];
      supplyChain: SupplyChainStep[];
    }
    ```

*   **`users` Collection:** Stores user-specific data, keyed by their Firebase Authentication UID.
    ```typescript
    // /users/{userId}
    interface User {
      uid: string; // Firebase Auth UID
      email: string;
      impactStats: { savedCO2: number; };
      wishlist: string[]; // Array of productIds
    }
    ```

*   **`chats` Subcollection:** Nests chat histories under each user, organized by product.
    ```typescript
    // /users/{userId}/chats/{productId}
    interface ChatSession {
      productId: string;
      lastUpdated: Timestamp;
      messages: { role: 'user' | 'model'; content: string; }[];
    }
    ```

#### 3.2. Firestore Security Rules

Rules are defined to protect data, ensuring users can only access their own information while product data remains publicly readable.

```javascript
// firestore.rules
rules_version = '2';
service cloud.firestore {
  match /databases/{database}/documents {
    // Products are public to read, but only admins can write.
    match /products/{productId} {
      allow read: if true;
      allow write: if request.auth.token.admin === true;
    }

    // Users can only read and write their own data.
    match /users/{userId} {
      allow read, update, create: if request.auth.uid == userId;
    }

    // Users can only access their own chat history.
    match /users/{userId}/chats/{chatId} {
      allow read, write: if request.auth.uid == userId;
    }
  }
}
```

#### 3.3. Google Cloud Storage for Assets

Cloud Storage houses all binary files, primarily images.

*   **Folder Structure:** A programmatic structure links assets directly to their Firestore documents.
    *   `products/{productId}/image_1024x1024.jpg`
    *   `products/{productId}/ar_overlay.png`
*   **Security Rules:** Rules allow public read access for all product assets but restrict write access to authenticated administrators.
*   **Optimization:**
    *   **Automated Resizing:** A Cloud Function is triggered on image upload to automatically create optimized thumbnails (e.g., 400x400) for faster loading in the feed view.
    *   **Global CDN:** Assets are automatically served via Google's global CDN for low-latency delivery worldwide.

---

### 4. Core Feature Implementation Details

#### 4.1. Augmented Reality (AR) Virtual Try-On

The AR feature is implemented using web-native technologies for maximum compatibility and performance, avoiding the overhead of heavy 3D libraries.

*   **Recommended Technology:** **HTML5 `getUserMedia` API + Canvas API**. This lightweight stack is perfectly suited for overlaying a 2D transparent PNG onto a live camera feed. It provides direct control over rendering and gestures without unnecessary complexity.
*   **`ARView.tsx` Component Architecture:**
    *   **Camera Access:** A `useEffect` hook manages the camera lifecycle, requesting the rear-facing (`environment`) camera stream via `getUserMedia` on mount and releasing it on unmount.
    *   **Canvas Rendering:** A `<canvas>` element is absolutely positioned over the `<video>` feed. A render function redraws the `overlayImage` on the canvas whenever the garment's transformation state changes, using canvas context methods (`translate`, `rotate`, `scale`).
    *   **State Management:** Local `useState` hook manages the garment's transformation object: `{ x, y, scale, rotation }`.
    *   **Gesture Handling:** Touch event listeners (`onTouchStart`, `onTouchMove`) on a container div detect single-finger drags (for movement or rotation based on a selected mode) and two-finger gestures (for intuitive rotation). A standard HTML `<input type="range">` slider controls scaling.

#### 4.2. AI-Powered Services (Gemini & Cloud Functions)

The AI features are implemented as two distinct serverless microservices to ensure security and separation of concerns. The Next.js frontend never directly interacts with the Gemini API.

*   **Service 1: EcoBot Stylist (`generateStylingAdvice`)**
    *   **Trigger:** An HTTP-triggered Cloud Function (`POST`).
    *   **Logic:** Receives the product context and entire chat history from the client. It prepends a system instruction to establish the "EcoBot" persona: *"You are EcoBot, an expert sustainable fashion stylist..."*.
    *   **Model:** `gemini-2.5-flash`, configured for a real-time chat experience.
    *   **API Contract:**
        *   **Request:** `POST { productContext, chatHistory }`
        *   **Response:** `200 OK { reply: "..." }`

*   **Service 2: Automated Sustainability Analysis (`analyzeSustainability`)**
    *   **Trigger:** An HTTP-triggered Cloud Function (`POST`).
    *   **Logic:** Receives key product attributes (name, materials, score). It constructs a specific, one-shot prompt to generate a brief, encouraging analysis: *"As a sustainability expert... write a brief 'Eco-Analysis'..."*.
    *   **Model:** `gemini-2.5-flash`, with a lower temperature (`0.4`) for more consistent, factual outputs.
    *   **API Contract:**
        *   **Request:** `POST { productName, materials, sustainabilityScore }`
        *   **Response:** `200 OK { analysis: "..." }`

*   **Security & Best Practices:**
    *   The Gemini API key is stored securely as an environment variable in the Cloud Function settings.
    *   IAM roles (`roles/cloudfunctions.invoker`) are used to ensure only the authenticated application can invoke these functions.
    *   Results from the `analyzeSustainability` function can be cached in the product's Firestore document to reduce costs and latency on subsequent views.

## Intermediate Steps

### Task Divider

Task Breakdown:
The user wants a comprehensive technical architecture for the 'EcoFitAR' application. The provided brief is detailed, covering frontend, backend, AI, and AR components. I will break down the task based on these distinct technological pillars. Each pillar can be architected independently before being integrated.

1.  **Frontend & Core UX:** Focuses on the user-facing application structure using Next.js.
2.  **Backend & Data Management:** Focuses on the data models, storage, and security using Firebase and Google Cloud Storage.
3.  **Augmented Reality (AR) Feature:** A specialized task focusing solely on the complex technical implementation of the virtual try-on.
4.  **AI Services Integration:** Focuses on the backend logic and infrastructure for the two distinct Gemini-powered features.

This approach ensures that each major component of the application gets a dedicated and detailed architectural plan. The subtasks are independent because the frontend architecture can be designed based on API contracts, the backend can be designed without knowing the specific UI implementation, and the AR and AI components are self-contained modules that can be developed in isolation.

Subtasks:
- Next.js App Router and Component Architecture: Design the complete frontend architecture using the Next.js App Router. Detail the component structure (e.g., Navbar, ProductCard, ARView, GeminiStylist), routing strategy for the different view states (FEED, PRODUCT_DETAILS, AR_TRY_ON, STYLIST_CHAT), and state management approach. The focus should be on creating a modular, scalable, and performant user interface according to the brief. (From Frontend and User Experience perspective)
- Firebase Firestore and Cloud Storage Data Architecture: Architect the backend infrastructure using Google Firebase and Cloud Storage. Define the NoSQL data models for Products, Users, and Supply Chain steps in Firestore. Plan the security rules to protect data. Detail the file storage strategy for product images and AR overlay PNGs in Google Cloud Storage, including access control and optimization. (From Backend and Data Management perspective)
- AR Virtual Try-On Technical Implementation Plan: Create a detailed technical plan for implementing the AR Virtual Try-On feature. Evaluate and recommend the best technology stack for a web-based AR experience (e.g., WebXR, Three.js, a specific AR library). Architect the 'ARView' component, detailing how it will access the device camera, render the garment overlay, and handle the specified gesture-based controls (drag, rotate, scale) within the Next.js application. (From Augmented Reality Integration perspective)
- Gemini AI Services Architecture with Cloud Functions: Design the architecture for the two AI-powered services using Google Cloud Functions and the Gemini API. Detail the creation of two separate, secure HTTP-triggered Cloud Functions: one for the 'EcoBot Stylist' (handling real-time chat with a specific persona) and one for the 'Automated Sustainability Analysis' (generating product descriptions). Specify the system prompts, model parameters (e.g., gemini-2.5-flash), and API request/response formats for each function. (From AI Services and Backend Logic perspective)

**Metadata:**
```json
{
  "reasoning": "The user wants a comprehensive technical architecture for the 'EcoFitAR' application. The provided brief is detailed, covering frontend, backend, AI, and AR components. I will break down the task based on these distinct technological pillars. Each pillar can be architected independently before being integrated.\n\n1.  **Frontend & Core UX:** Focuses on the user-facing application structure using Next.js.\n2.  **Backend & Data Management:** Focuses on the data models, storage, and security using Firebase and Google Cloud Storage.\n3.  **Augmented Reality (AR) Feature:** A specialized task focusing solely on the complex technical implementation of the virtual try-on.\n4.  **AI Services Integration:** Focuses on the backend logic and infrastructure for the two distinct Gemini-powered features.\n\nThis approach ensures that each major component of the application gets a dedicated and detailed architectural plan. The subtasks are independent because the frontend architecture can be designed based on API contracts, the backend can be designed without knowing the specific UI implementation, and the AR and AI components are self-contained modules that can be developed in isolation.",
  "subtasks": [
    {
      "title": "Next.js App Router and Component Architecture",
      "description": "Design the complete frontend architecture using the Next.js App Router. Detail the component structure (e.g., Navbar, ProductCard, ARView, GeminiStylist), routing strategy for the different view states (FEED, PRODUCT_DETAILS, AR_TRY_ON, STYLIST_CHAT), and state management approach. The focus should be on creating a modular, scalable, and performant user interface according to the brief.",
      "id": "frontend_architecture",
      "perspective": "Frontend and User Experience"
    },
    {
      "id": "backend_data_architecture",
      "title": "Firebase Firestore and Cloud Storage Data Architecture",
      "perspective": "Backend and Data Management",
      "description": "Architect the backend infrastructure using Google Firebase and Cloud Storage. Define the NoSQL data models for Products, Users, and Supply Chain steps in Firestore. Plan the security rules to protect data. Detail the file storage strategy for product images and AR overlay PNGs in Google Cloud Storage, including access control and optimization."
    },
    {
      "id": "ar_feature_implementation",
      "title": "AR Virtual Try-On Technical Implementation Plan",
      "description": "Create a detailed technical plan for implementing the AR Virtual Try-On feature. Evaluate and recommend the best technology stack for a web-based AR experience (e.g., WebXR, Three.js, a specific AR library). Architect the 'ARView' component, detailing how it will access the device camera, render the garment overlay, and handle the specified gesture-based controls (drag, rotate, scale) within the Next.js application.",
      "perspective": "Augmented Reality Integration"
    },
    {
      "id": "ai_services_architecture",
      "title": "Gemini AI Services Architecture with Cloud Functions",
      "perspective": "AI Services and Backend Logic",
      "description": "Design the architecture for the two AI-powered services using Google Cloud Functions and the Gemini API. Detail the creation of two separate, secure HTTP-triggered Cloud Functions: one for the 'EcoBot Stylist' (handling real-time chat with a specific persona) and one for the 'Automated Sustainability Analysis' (generating product descriptions). Specify the system prompts, model parameters (e.g., gemini-2.5-flash), and API request/response formats for each function."
    }
  ]
}
```

### Frontend and User Experience Specialist

Here is a comprehensive technical architecture for the EcoFitAR frontend, focusing on the Next.js App Router, component structure, and state management, as requested.

---

### **EcoFitAR: Next.js App Router and Component Architecture**

This document details the frontend architecture for the EcoFitAR platform, designed using the Next.js App Router. The architecture prioritizes a modular structure, performance via Server Components, and a seamless user experience through a well-defined routing and state management strategy.

#### **1. Directory Structure**

The project will follow the standard Next.js `app` directory structure to leverage its powerful features like nested layouts and Server Components.

```plaintext
/app
├── (main)                                # Route group for views with the main Navbar
│   ├── layout.tsx                        # Main layout with Navbar
│   ├── page.tsx                          # The FEED view (Homepage)
│   └── product
│       └── [id]                          # Dynamic route for a single product
│           ├── page.tsx                  # PRODUCT_DETAILS view
│           └── stylist
│               └── page.tsx              # STYLIST_CHAT view
│
├── (immersive)                           # Route group for full-screen, no-nav views
│   └── product
│       └── [id]
│           └── try-on
│               └── page.tsx              # AR_TRY_ON view
│
├── api                                   # API Routes for client-side actions
│   ├── stylist
│   │   └── route.ts                      # Backend handler for GeminiStylist chat
│   └── sustainability-analysis
│       └── route.ts                      # Backend handler for Gemini analysis
│
├── components                            # Reusable UI components
│   ├── ar                                # AR-specific components
│   │   └── ARView.tsx                    # (Client Component)
│   ├── chat                              # Chat-specific components
│   │   └── GeminiStylist.tsx             # (Client Component)
│   ├── layout                            # Layout components
│   │   └── Navbar.tsx                    # (Client Component)
│   ├── product                           # Product-related components
│   │   ├── ProductCard.tsx               # (Server Component)
│   │   └── SustainabilityTracker.tsx     # (Server Component)
│   └── ui                                # Generic UI primitives (buttons, sliders, etc.)
│
├── lib                                   # Helper functions, Firebase config, etc.
│   ├── firebase.ts                       # Firebase client/admin SDK initialization
│   ├── gemini.ts                         # Gemini API interaction logic
│   └── data.ts                           # Data fetching functions (e.g., getProductById)
│
└── layout.tsx                            # Root layout (<html>, <body>)
```

#### **2. Routing Strategy: Mapping View States to Routes**

The application's "View States" are mapped directly to Next.js routes, creating a shareable and robust navigation system. We use Route Groups `(main)` and `(immersive)` to apply different layouts to different sections of the app without affecting the URL structure.

*   **FEED (`/`):**
    *   **Route:** `app/(main)/page.tsx`
    *   **Description:** The main landing page. It will be a **Server Component** that fetches the "Trending Sustainable" products directly from Firestore on the server and passes the data down to `<ProductCard>` components. This ensures a fast initial load time and is SEO-friendly.

*   **PRODUCT_DETAILS (`/product/[id]`):**
    *   **Route:** `app/(main)/product/[id]/page.tsx`
    *   **Description:** A dynamic route that displays details for a specific product. This page will be an `async` **Server Component**. It uses the `id` from the URL parameters to fetch the corresponding product data from Firestore. It then renders server-side components like `<SustainabilityTracker>` and placeholders for client-side interactive elements.

*   **STYLIST_CHAT (`/product/[id]/stylist`):**
    *   **Route:** `app/(main)/product/[id]/stylist/page.tsx`
    *   **Description:** The AI stylist chat interface. This route reuses the `(main)` layout, so the `Navbar` remains visible. The page itself will fetch the initial product data on the server to provide context to the chat component, which will be a Client Component.

*   **AR_TRY_ON (`/product/[id]/try-on`):**
    *   **Route:** `app/(immersive)/product/[id]/try-on/page.tsx`
    *   **Description:** The immersive AR view. By placing this route in the `(immersive)` group, it will not inherit the main layout containing the `Navbar`. This allows for a true full-screen experience dedicated entirely to the AR interface, as specified in the brief.

#### **3. Component Architecture: Server vs. Client Components**

The architecture leverages the App Router's hybrid model, using Server Components for performance and static rendering, and Client Components for interactivity.

*   **`Navbar.tsx` (Client Component)**
    *   **Purpose:** Provides persistent navigation. The central, elevated AR button provides a shortcut to the AR view.
    *   **Type:** `Client Component` (`'use client'`).
    *   **Reasoning:** It requires client-side hooks like `usePathname` to highlight the active link and `useState` for handling the mobile menu toggle. It will use the `<Link>` component from `next/link` for client-side navigation.

*   **`ProductCard.tsx` (Server Component)**
    *   **Purpose:** Displays a product summary in the FEED view.
    *   **Type:** `Server Component` (default).
    *   **Reasoning:** This component is purely presentational. It receives product data as props and renders HTML. It has no interactive logic, making it a perfect candidate for server rendering to reduce the client-side JavaScript bundle. It will be wrapped in a Next.js `<Link>` tag to navigate to the product details page.

*   **`SustainabilityTracker.tsx` (Server Component)**
    *   **Purpose:** Visualizes the product's supply chain timeline.
    *   **Type:** `Server Component`.
    *   **Reasoning:** Like the `ProductCard`, this component receives the `supplyChain` array as a prop and renders a static view. It involves mapping over data and displaying it, with no user interaction required.

*   **`ARView.tsx` (Client Component)**
    *   **Purpose:** The core AR try-on experience.
    *   **Type:** `Client Component` (`'use client'`).
    *   **Reasoning:** This is the most interactive part of the application. It needs access to browser-only APIs (camera via `navigator.mediaDevices`), manages complex state for the garment's position, rotation, and scale (`useState`, `useReducer`), and handles user touch events. This component cannot be rendered on the server.

*   **`GeminiStylist.tsx` (Client Component)**
    *   **Purpose:** The conversational UI for the EcoBot Stylist.
    *   **Type:** `Client Component` (`'use client'`).
    *   **Reasoning:** It manages the chat history (`useState`), handles form submissions, and makes client-side `fetch` requests to our API route (`/api/stylist`) to get responses from the Gemini AI. All user input and dynamic message rendering must happen on the client.

*   **`EcoAnalysis.tsx` (Client Component)**
    *   **Purpose:** Displays the AI-generated sustainability analysis on the product details page.
    *   **Type:** `Client Component` (`'use client'`).
    *   **Reasoning:** While the parent product page is a Server Component, this specific section needs to manage its own loading state ("Analyzing sustainability impact...") and then fetch the analysis from the `/api/sustainability-analysis` endpoint after the initial page load. This prevents the initial page render from being blocked by the AI generation and provides a better user experience.

#### **4. State Management Strategy**

A hybrid approach to state management is employed to ensure efficiency and simplicity.

1.  **URL as State (Primary):** The Next.js App Router is the primary state manager. The current view and the selected product are always represented in the URL (e.g., `/product/organic-hemp-jacket`). This makes the application's state bookmarkable, shareable, and resilient to page refreshes. We use `useParams()` in components to access dynamic segments like the product `id`.

2.  **Component-Local State (`useState`, `useReducer`):** For state that is confined to a single component, standard React hooks are used.
    *   **Example:** In `ARView.tsx`, `useState` will manage the current transformation values (position, rotation, scale) of the garment overlay.
    *   **Example:** In `GeminiStylist.tsx`, `useState` will manage the user's current input and the array of chat messages.

3.  **Shared Client State (Zustand):** For minimal global state that needs to be shared across different Client Components without prop drilling, a lightweight library like **Zustand** is recommended over the more boilerplate-heavy Redux or the re-render complexities of React Context for dynamic data.
    *   **Use Case:** Managing the "Your Impact" data (`12kg of CO2 saved`). This data might be fetched once and then displayed in the `Navbar` and on the `FEED` page. A Zustand store can hold this value and allow any client component to subscribe to it.

    ```typescript
    // Example store in /lib/store.ts
    import { create } from 'zustand';

    interface ImpactState {
      co2Saved: number;
      setCo2Saved: (amount: number) => void;
    }

    export const useImpactStore = create<ImpactState>((set) => ({
      co2Saved: 0,
      setCo2Saved: (amount) => set({ co2Saved: amount }),
    }));
    ```

**Metadata:**
```json
{
  "subtask_id": "frontend_architecture",
  "title": "Next.js App Router and Component Architecture",
  "perspective": "Frontend and User Experience"
}
```

### Backend and Data Management Specialist

Here is the comprehensive technical architecture for the backend infrastructure of the EcoFitAR platform, focusing on Firebase Firestore and Google Cloud Storage.

---

### **Backend and Data Management: Firebase & Cloud Storage Architecture**

The backend for EcoFitAR is designed on a serverless model using Google's Firebase platform, specifically Firestore for the NoSQL database and Cloud Storage for asset management. This architecture ensures high scalability, real-time data synchronization, and robust security with minimal server-side maintenance.

### 1. Firebase Firestore Data Architecture

Firestore will serve as the primary database, storing all application data in a collection-document model. This structure is flexible and optimized for the complex, nested data required by the platform's features.

#### 1.1 Collections Overview

The database will be organized around two primary top-level collections: `products` and `users`.

*   **`products`**: This collection holds the entire curated catalog of sustainable clothing. It is designed for efficient querying to populate the main feed and product detail pages.
*   **`users`**: This collection stores user-specific information, including authentication details, personalization data, and impact metrics. It also serves as a root for user-specific subcollections like chat history.

#### 1.2 NoSQL Data Models

**1.2.1 `products` Collection**

Each document in this collection represents a single product. The document ID will be a unique, auto-generated string. The `supplyChain` data is embedded directly as an array of objects within the product document for efficient retrieval, as it is always displayed with the product.

*   **Collection:** `products`
*   **Document:** `{productId}`
*   **Structure:**

```typescript
// /products/{productId}
interface Product {
  id: string; // Document ID
  name: string; // "Organic Hemp Utility Jacket"
  brand: string; // "EarthWear"
  price: number; // 129.00
  image: string; // URL to main product image in Cloud Storage
  overlayImage: string; // URL to transparent PNG for AR in Cloud Storage
  sustainabilityScore: number; // 98 (0-100)
  carbonFootprint: string; // "5.2 kg CO2e"
  materials: string[]; // ["100% Organic Hemp", "Recycled Brass Buttons"]
  createdAt: Timestamp;
  supplyChain: SupplyChainStep[];
}

interface SupplyChainStep {
  stage: string; // "Raw Material" | "Assembly" | "Shipping" | "Retail"
  location: string; // "Ghent, Belgium"
  date: Timestamp;
  verified: boolean; // true
  icon: string; // "farm" | "factory" | "shipping" | "store"
}
```

**1.2.2 `users` Collection**

Each document represents a user, keyed by their Firebase Authentication UID. This ensures a direct and secure link between the authenticated user and their data.

*   **Collection:** `users`
*   **Document:** `{userId}` (matches Firebase Auth UID)
*   **Structure:**

```typescript
// /users/{userId}
interface User {
  uid: string; // Firebase Auth UID
  email: string;
  displayName: string;
  createdAt: Timestamp;
  impactStats: {
    savedCO2: number; // 12 (in kg)
    itemsPurchased: number;
  };
  wishlist: string[]; // Array of productIds
}
```

**1.2.3 `chats` Subcollection**

To store conversations with the EcoBot Stylist, a subcollection is nested under each user document. This isolates chat data per user and allows for easy retrieval of conversation history for a specific product.

*   **Path:** `users/{userId}/chats/{productId}`
*   **Structure:** Each document represents a full conversation about a single product and contains an array of messages.

```typescript
// /users/{userId}/chats/{productId}
interface ChatSession {
  productId: string;
  productName: string; // "Organic Hemp Utility Jacket"
  lastUpdated: Timestamp;
  messages: ChatMessage[];
}

interface ChatMessage {
  role: 'user' | 'model';
  content: string;
  timestamp: Timestamp;
}
```

### 2. Firestore Security Rules

Security rules are critical for protecting data integrity and user privacy. The rules are defined with a "default deny" posture, explicitly allowing access where needed.

```javascript
// firestore.rules
rules_version = '2';

service cloud.firestore {
  match /databases/{database}/documents {

    // Helper function to check for admin role
    function isAdmin() {
      return request.auth.token.admin === true;
    }

    // --- PRODUCTS COLLECTION ---
    // Anyone can read the product catalog.
    // Only admins can create, update, or delete products.
    match /products/{productId} {
      allow read: if true;
      allow write: if isAdmin();

      // Data Validation on write
      allow create: if isAdmin() &&
                      request.resource.data.name is string &&
                      request.resource.data.price is number &&
                      request.resource.data.sustainabilityScore is number &&
                      request.resource.data.sustainabilityScore >= 0 &&
                      request.resource.data.sustainabilityScore <= 100;
    }

    // --- USERS COLLECTION ---
    // Users can only read and write their own document.
    // A user can create their own document upon signup.
    match /users/{userId} {
      allow read, update: if request.auth.uid == userId;
      allow create: if request.auth.uid == userId;
    }

    // --- CHATS SUBCOLLECTION ---
    // Users can only read and write their own chat history.
    match /users/{userId}/chats/{productId} {
      allow read, write: if request.auth.uid == userId;
    }
  }
}
```

### 3. Google Cloud Storage Architecture

Cloud Storage will house all binary assets, primarily product images and the transparent PNGs required for the AR virtual try-on feature.

#### 3.1 File Storage Strategy & Folder Structure

A clear, programmatic folder structure is essential for organization and for writing effective security rules. Files will be organized by type and keyed by the unique `productId` from Firestore.

*   **Main Bucket:** `[your-project-id].appspot.com`
*   **Folder Structure:**
    *   `products/{productId}/`
        *   `image_1024x1024.jpg` (Main product image)
        *   `image_400x400.jpg` (Thumbnail for feed view)
        *   `ar_overlay.png` (Transparent PNG for AR feature)
    *   `users/{userId}/`
        *   `profile_image.jpg` (Optional user profile pictures)

#### 3.2 Access Control & Security Rules

Storage security rules ensure that assets are publicly readable but that upload/delete permissions are tightly controlled.

```javascript
// storage.rules
rules_version = '2';

service firebase.storage {
  match /b/{bucket}/o {

    // Helper function to check for admin role
    function isAdmin() {
      return request.auth.token.admin === true;
    }

    // --- PRODUCT ASSETS ---
    // All product images and AR overlays are publicly readable.
    // Only admins can upload, modify, or delete these files.
    // We also enforce file type and size.
    match /products/{productId}/{fileName} {
      allow read: if true;
      allow write: if isAdmin() &&
                     request.resource.size < 5 * 1024 * 1024 && // Max 5MB
                     request.resource.contentType.matches('image/.*');
    }

    // --- USER ASSETS ---
    // Users can only upload/manage their own profile picture.
    match /users/{userId}/{fileName} {
      allow read: if true; // Profile pictures are public
      allow write: if request.auth.uid == userId;
    }
  }
}
```

#### 3.3 Optimization and Content Delivery

1.  **Automated Image Resizing:** To optimize performance, especially for the main product feed, we will use a **Cloud Function**. This function will be triggered whenever a new image is uploaded to the `products/{productId}/` path. It will automatically generate optimized versions (e.g., a `400x400` thumbnail) and save them in the same folder, ensuring the mobile app downloads only the size it needs.

2.  **Global CDN Delivery:** All assets stored in Google Cloud Storage are automatically served via Google's global Content Delivery Network (CDN). This provides low-latency access to images for users anywhere in the world without any additional configuration, which is critical for a smooth and fast user experience.

3.  **File Naming Convention:** Using the unique Firestore `{productId}` in the storage path ensures there are no naming collisions and creates a direct, predictable link between a product's data in Firestore and its assets in Cloud Storage.

**Metadata:**
```json
{
  "subtask_id": "backend_data_architecture",
  "title": "Firebase Firestore and Cloud Storage Data Architecture",
  "perspective": "Backend and Data Management"
}
```

### Augmented Reality Integration Specialist

### **AR Virtual Try-On: Technical Implementation Plan**

This document provides a detailed technical plan for implementing the AR Virtual Try-On feature for the EcoFitAR platform. It evaluates the optimal technology stack for a web-based experience and outlines the architecture of the `ARView` component within the Next.js App Router framework.

---

#### **1. Technology Stack Evaluation and Recommendation**

The core requirement is to overlay a 2D transparent PNG of a garment onto a live camera feed and allow user manipulation. This is a form of "Augmented Image" rather than true 3D spatial Augmented Reality. Based on this, we evaluate the following options:

| Technology | Pros | Cons | Suitability for EcoFitAR |
| :--- | :--- | :--- | :--- |
| **HTML5 `getUserMedia` + Canvas API** | - **Lightweight & Performant:** No heavy libraries needed. <br>- **Universal Browser Support:** `getUserMedia` and `Canvas` are mature web standards. <br>- **Direct Control:** Full, low-level control over rendering and gesture handling. <br>- **Perfect Fit:** Ideally suited for 2D image manipulation on a video stream. | - **Manual Implementation:** Requires writing gesture logic from scratch. <br>- **Not "True" AR:** Doesn't provide world-tracking or surface detection. | **Highly Recommended**. This is the most pragmatic, efficient, and direct approach to achieve the specified functionality without unnecessary complexity. |
| **WebXR Device API** | - **Future-Proof:** The official standard for web-based immersive experiences. <br>- **Powerful:** Enables true spatial AR (placing 3D models in the user's environment). <br>- **World Understanding:** Can detect planes, anchors, and track the device's position in 3D space. | - **Overkill:** Massively over-engineered for a simple 2D overlay task. <br>- **Complexity:** Requires setting up a 3D scene (e.g., with Three.js) and managing an XR session. <br>- **Inconsistent Support:** Browser and device support is still evolving. | **Not Recommended for Initial Build**. While powerful, its complexity introduces significant overhead for a feature that doesn't require 3D space. It should be considered only if the roadmap includes evolving to 3D garment models. |
| **Three.js / react-three-fiber** | - **Excellent for 3D:** The de-facto standard for 3D graphics on the web. <br>- **Rich Ecosystem:** Large community and extensive features. <br>- **React Integration:** `react-three-fiber` makes it easy to use in Next.js. | - **3D-Centric:** Using it to render a 2D plane in front of a video background is an inefficient use of the library. <br>- **Increased Bundle Size:** Adds a significant dependency for a simple task. | **Not Recommended**. The problem is fundamentally 2D. Introducing a 3D rendering engine adds unnecessary performance and bundle size costs. |

**Recommendation:**

The recommended approach is to use the native **HTML5 `getUserMedia` API combined with the Canvas API**. This stack is lightweight, universally supported, and provides the exact level of control needed to render a video feed and manipulate a 2D image on top of it. It avoids the steep learning curve and performance overhead of 3D-focused AR libraries, ensuring a fast, responsive user experience on a wide range of mobile devices.

---

#### **2. `ARView` Component Architecture**

The `ARView` component will be a client-side component (`'use client'`) in the Next.js App Router. It will manage the camera stream, canvas rendering, and all user interactions.

##### **2.1. Component Structure and State Management**

We will use React hooks (`useState`, `useRef`, `useEffect`) to manage the component's state and lifecycle.

```typescript
// app/components/ARView.tsx

'use client';

import { useState, useRef, useEffect, TouchEvent } from 'react';

// Interface for the garment's transformation properties
interface GarmentTransform {
  x: number;
  y: number;
  scale: number;
  rotation: number; // in degrees
}

// Props for the component
interface ARViewProps {
  productName: string;
  overlayImageUrl: string;
  onClose: () => void;
}

export default function ARView({ productName, overlayImageUrl, onClose }: ARViewProps) {
  // State for gesture mode and garment transformations
  const [mode, setMode] = useState<'MOVE' | 'ROTATE'>('MOVE');
  const [transform, setTransform] = useState<GarmentTransform>({ x: 0, y: 0, scale: 1, rotation: 0 });

  // Refs for DOM elements and interaction state
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const garmentImageRef = useRef<HTMLImageElement | null>(null);
  const touchStartRef = useRef<{ x: number, y: number } | null>(null); // For drag calculations

  // ... useEffect for camera setup ...
  // ... useEffect for canvas drawing ...
  // ... Handlers for gestures and UI controls ...

  return (
    // ... JSX for the component ...
  );
}
```

##### **2.2. Camera Access and Video Stream**

We'll use a `useEffect` hook to initialize the camera when the component mounts and clean up when it unmounts.

1.  **Request Camera:** On mount, call `navigator.mediaDevices.getUserMedia`. We will specifically request the rear-facing camera (`facingMode: 'environment'`) as preferred.
2.  **Attach Stream:** If permission is granted, the resulting `MediaStream` is attached to the `srcObject` of the `<video>` element.
3.  **Cleanup:** The `useEffect` return function will stop all tracks on the `MediaStream` to release the camera when the user navigates away.

```typescript
// Inside ARView component

useEffect(() => {
  let stream: MediaStream | null = null;

  const startCamera = async () => {
    try {
      stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'environment' },
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
    } catch (err) {
      console.error("Error accessing camera:", err);
      // Handle error: show a message to the user
    }
  };

  startCamera();

  return () => {
    stream?.getTracks().forEach(track => track.stop());
  };
}, []);
```

##### **2.3. Garment Overlay and Canvas Rendering**

The garment PNG will be drawn onto a `<canvas>` element positioned directly over the `<video>` element.

1.  **Load Image:** An `Image` object is created to preload the `overlayImageUrl`.
2.  **Render Loop:** A `draw` function will be responsible for rendering the garment. It will be called whenever the `transform` state changes.
3.  **Transformations:** The canvas context's transformation methods (`translate`, `rotate`, `scale`) will be used to apply the user's manipulations before drawing the image with `drawImage`.

```typescript
// Inside ARView component

// Effect to load the image and draw on canvas when transform changes
useEffect(() => {
  const canvas = canvasRef.current;
  const ctx = canvas?.getContext('2d');
  if (!ctx || !canvas) return;

  const draw = (img: HTMLImageElement) => {
    // Set canvas dimensions to match video element for proper scaling
    canvas.width = videoRef.current?.clientWidth || 0;
    canvas.height = videoRef.current?.clientHeight || 0;
    
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    
    // Center of the canvas (initial position)
    const centerX = canvas.width / 2;
    const centerY = canvas.height / 2;

    ctx.save();
    // Apply transformations from state
    ctx.translate(centerX + transform.x, centerY + transform.y);
    ctx.rotate((transform.rotation * Math.PI) / 180);
    ctx.scale(transform.scale, transform.scale);

    // Draw image centered on the transformation point
    ctx.drawImage(img, -img.width / 2, -img.height / 2);
    ctx.restore();
  };

  if (garmentImageRef.current) {
    draw(garmentImageRef.current);
  } else {
    const img = new Image();
    img.src = overlayImageUrl;
    img.onload = () => {
      garmentImageRef.current = img;
      draw(img);
    };
  }
}, [transform, overlayImageUrl]);
```

##### **2.4. Gesture-Based Controls Implementation**

We will attach touch event listeners (`onTouchStart`, `onTouchMove`, `onTouchEnd`) to a container div that wraps both the video and the canvas.

*   **Movement (Drag):**
    *   On `onTouchStart` with one finger, record the initial touch coordinates.
    *   On `onTouchMove`, calculate the delta between the current and initial coordinates.
    *   If `mode` is `'MOVE'`, update the `transform.x` and `transform.y` state with this delta.

*   **Rotation:**
    *   **Two-Finger Twist (Recommended):** On `onTouchMove` with two fingers, calculate the angle formed by the two touch points. The change in this angle from the previous frame determines the rotation delta. This provides the most intuitive rotation control.
    *   **Horizontal Swipe (Alternative):** If `mode` is `'ROTATE'`, a single-finger `onTouchMove` will map the horizontal movement (`deltaX`) to a change in `transform.rotation`. For example, every 5 pixels of horizontal movement could equal 1 degree of rotation.

*   **Scaling:**
    *   This will be handled by a dedicated HTML range slider (`<input type="range">`).
    *   The slider's `onChange` event will directly update the `transform.scale` state. Its `min`, `max`, and `step` attributes will be set to `0.5`, `1.5`, and `0.01` respectively.

*   **UI Controls:**
    *   **Mode Toggle:** Buttons for "MOVE" and "ROTATE" will set the `mode` state, changing the behavior of single-finger drag.
    *   **Reset Button:** An `onClick` handler will reset the `transform` state to its initial values: `{ x: 0, y: 0, scale: 1, rotation: 0 }`.

##### **2.5. JSX and Styling**

The JSX will consist of a full-screen container with the video and canvas elements layered using CSS `position: absolute`. The UI controls will be overlaid on top.

```jsx
// Simplified JSX structure within ARView component

<div className="fixed inset-0 bg-black">
  {/* Camera Feed */}
  <video ref={videoRef} autoPlay playsInline className="w-full h-full object-cover" />

  {/* Garment Overlay */}
  <canvas ref={canvasRef} className="absolute top-0 left-0 w-full h-full" />

  {/* UI Controls Overlay */}
  <div className="absolute top-0 left-0 w-full h-full p-4 flex flex-col justify-between">
    {/* Top Bar: Close button, Product Name */}
    <div className="flex justify-between items-center text-white">
      <button onClick={onClose}>Close</button>
      <div>
        <p>{productName}</p>
        <p className="text-sm text-green-400">98% Match</p>
      </div>
    </div>

    {/* Bottom Controls */}
    <div className="flex flex-col items-center space-y-4">
      {/* Scale Slider */}
      <input 
        type="range" 
        min="0.5" 
        max="1.5" 
        step="0.01" 
        value={transform.scale}
        onChange={(e) => setTransform(t => ({ ...t, scale: parseFloat(e.target.value) }))}
      />
      {/* Mode Toggles & Reset */}
      <div className="flex space-x-2">
        <button onClick={() => setMode('MOVE')}>MOVE</button>
        <button onClick={() => setMode('ROTATE')}>ROTATE</button>
        <button onClick={handleReset}>RESET</button>
      </div>
    </div>
  </div>
</div>
```

**Metadata:**
```json
{
  "subtask_id": "ar_feature_implementation",
  "title": "AR Virtual Try-On Technical Implementation Plan",
  "perspective": "Augmented Reality Integration"
}
```

### AI Services and Backend Logic Specialist

### **Gemini AI Services Architecture: Cloud Functions Backend**

This document details the technical architecture for the two core AI services powering the EcoFitAR platform: the **EcoBot Stylist** and the **Automated Sustainability Analysis**. Both services will be implemented as secure, scalable, and independent serverless microservices using Google Cloud Functions, which will act as a secure backend layer between the Next.js frontend and the Google Gemini API.

---

#### **1. Overall Architectural Diagram**

The interaction between the Next.js client, Cloud Functions, and the Gemini API follows a simple, secure pattern:

```
+----------------+      (1) HTTPS Request       +---------------------+      (3) API Call       +-----------------+
|                |  (Authenticated w/ IAM)  --> |                     |  (Server-to-Server)  --> |                 |
|   Next.js App  |                              |  Google Cloud       |                        |   Google AI     |
| (Client-side)  |                              |  Function           |                        | (Gemini API)    |
|                |  <-- (2) JSON Response     -- | (e.g., analyze... ) |  <-- (4) API Response  -- |                 |
+----------------+                              +---------------------+                        +-----------------+
```

**Benefits of this Architecture:**
*   **Security:** The Gemini API key is never exposed to the client. All requests are proxied through the Cloud Function, which authenticates the caller.
*   **Scalability:** Cloud Functions automatically scale with demand, ensuring the AI services remain responsive during traffic spikes.
*   -**Separation of Concerns:** The complex logic of prompt engineering, model configuration, and API interaction is encapsulated on the backend, keeping the Next.js frontend clean and focused on the user experience.

---

#### **2. Service 1: EcoBot Stylist (`generateStylingAdvice`)**

This service provides a real-time, context-aware conversational chat experience.

**2.1. Cloud Function: `generateStylingAdvice`**

*   **Trigger:** HTTP Request (`POST`)
*   **Region:** Deployed in a region close to your user base (e.g., `us-central1`).
*   **Security:** Configured to require authentication. The Next.js backend (or a dedicated service account) will be granted the `roles/cloudfunctions.invoker` IAM role to securely call this function.
*   **Purpose:** To receive chat history and product context, construct a conversational prompt for Gemini, and stream back a helpful, on-brand response.

**2.2. System Prompt & Model Configuration**

The function will prepend a carefully crafted system instruction to every conversation to establish the AI's persona and goals.

*   **System Instruction:**
    ```
    You are EcoBot, an expert sustainable fashion stylist for an e-commerce app named EcoFitAR. You are helpful, concise, and passionate about the environment. Your goal is to provide practical, stylish advice that aligns with sustainable principles. Do not recommend products from other brands. Keep your answers to 2-3 sentences unless the user asks for more detail.
    ```
*   **Model:** `gemini-2.5-flash`
*   **Model Parameters:**
    *   `temperature`: `0.7` (To allow for creative and natural-sounding styling advice).
    *   `topP`: `0.95`
    *   `thinkingBudget`: `0` (As specified in the brief for a real-time chat experience, minimizing perceived latency).

**2.3. API Contract**

*   **Endpoint:** `https://<region>-<project-id>.cloudfunctions.net/generateStylingAdvice`
*   **Method:** `POST`
*   **Request Body (from Next.js app):** The request will send the current product's key details and the entire chat history to maintain conversational context.

    ```json
    {
      "productContext": {
        "name": "Organic Hemp Utility Jacket",
        "materials": ["100% Organic Hemp", "Recycled Brass Buttons", "Natural Indigo Dye"],
        "brand": "EarthWear"
      },
      "chatHistory": [
        { 
          "role": "user", 
          "parts": [{ "text": "Hi, I'm looking at the Organic Hemp Utility Jacket." }] 
        },
        { 
          "role": "model", 
          "parts": [{ "text": "Hi! That's a great choice. How can I help you style it sustainably?" }]
        },
        {
          "role": "user",
          "parts": [{ "text": "What shoes would look good with it for a casual weekend?" }]
        }
      ]
    }
    ```

*   **Success Response (to Next.js app):** A simple JSON object containing the model's generated text reply.

    ```json
    {
      "reply": "For a casual weekend look, I'd pair the jacket with minimalist sneakers made from recycled materials or a pair of comfortable cork sandals. Both options complement the jacket's natural texture while keeping your footprint light!"
    }
    ```

*   **Error Response (e.g., 400 Bad Request):**

    ```json
    {
      "error": "Invalid request: 'chatHistory' is a required field."
    }
    ```

---

#### **3. Service 2: Automated Sustainability Analysis (`analyzeSustainability`)**

This service provides a one-shot, AI-generated summary of a product's environmental benefits.

**3.1. Cloud Function: `analyzeSustainability`**

*   **Trigger:** HTTP Request (`POST`)
*   **Region:** Same as the other function for consistency.
*   **Security:** Also requires IAM-based authentication for invocation.
*   **Purpose:** To take key product attributes, generate a concise and encouraging eco-analysis, and return it as a string. This is a non-conversational, "one-and-done" call.

**3.2. System Prompt & Model Configuration**

The prompt is a direct instruction designed to produce a specific type of text for the product details page.

*   **User Prompt (constructed within the function):**
    ```
    As a sustainability expert for the EcoFitAR app, write a brief and encouraging 'Eco-Analysis' (2-3 sentences) for a customer viewing this product. Your tone should be positive and educational. Focus on the benefits of the materials and the high sustainability score.

    Product Data:
    - Name: Recycled Ocean Plastic Parka
    - Materials: 100% Recycled PET, Eco-friendly DWR Coating
    - Sustainability Score: 95/100
    ```
*   **Model:** `gemini-2.5-flash`
*   **Model Parameters:**
    *   `temperature`: `0.4` (Slightly lower to ensure the analysis is more factual and consistent across different products).
    *   `maxOutputTokens`: `128` (To keep the response concise).

**3.3. API Contract**

*   **Endpoint:** `https://<region>-<project-id>.cloudfunctions.net/analyzeSustainability`
*   **Method:** `POST`
*   **Request Body (from Next.js app):** Contains only the necessary data points for the analysis.

    ```json
    {
      "productName": "Recycled Ocean Plastic Parka",
      "materials": ["100% Recycled PET", "Eco-friendly DWR Coating"],
      "sustainabilityScore": 95
    }
    ```

*   **Success Response (to Next.js app):** A JSON object containing the complete analysis text.

    ```json
    {
      "analysis": "This parka is a powerful statement in sustainable fashion! By using 100% recycled PET, it directly helps reduce plastic pollution in our oceans. Its outstanding sustainability score of 95 reflects a deep commitment to protecting our planet."
    }
    ```

*   **Error Response (e.g., 500 Internal Server Error):**

    ```json
    {
      "error": "Failed to generate sustainability analysis from AI service."
    }
    ```

---

#### **4. Security and Implementation Best Practices**

*   **Environment Variables:** The `GEMINI_API_KEY` and Google Cloud `PROJECT_ID` will be stored securely as environment variables in the Cloud Function settings, never hardcoded in the source.
*   **IAM Permissions:** The service account running the Cloud Functions will be granted the `roles/aiplatform.user` role, providing the minimum necessary permissions to call the Gemini API on Vertex AI.
*   **Idempotency:** While the `analyzeSustainability` function is naturally idempotent (the same input yields the same output), consider caching its results in Firestore for a given product ID to reduce redundant API calls and lower costs. The chatbot function is stateful and cannot be cached in the same way.
*   **Error Handling:** Both functions will include robust `try...catch` blocks to handle potential failures during the Gemini API call and return meaningful HTTP status codes and error messages to the frontend.

**Metadata:**
```json
{
  "subtask_id": "ai_services_architecture",
  "title": "Gemini AI Services Architecture with Cloud Functions",
  "perspective": "AI Services and Backend Logic"
}
```

### Results Integrator

Here is a comprehensive technical architecture for the EcoFitAR Sustainable Commerce Platform, synthesizing expert perspectives on frontend, backend, data management, AR, and AI services.

---

### **EcoFitAR: Comprehensive Technical Architecture**

This document outlines the complete technical architecture for the EcoFitAR platform. It integrates a Next.js App Router frontend with a serverless Google Cloud backend, leveraging Firebase Firestore, Cloud Storage, and Cloud Functions to power the platform's core features, including AR virtual try-on and Gemini-powered AI services.

### 1. Overall System Architecture

EcoFitAR is designed as a modern, scalable web application. The architecture separates concerns into three primary layers that work in concert:

1.  **Frontend (Next.js):** A performant, mobile-first single-page application built with the Next.js App Router. It uses a hybrid of Server Components for fast initial loads and SEO, and Client Components for rich interactivity.
2.  **Backend & Data (Firebase):** A serverless backend using Firebase services. **Firestore** acts as the NoSQL database for all application data, **Cloud Storage** hosts all media assets like product images and AR overlays, and **Firebase Authentication** manages user identity.
3.  **AI Services (Google Cloud Functions & Gemini):** A secure backend-for-frontend (BFF) layer built with Cloud Functions. These serverless functions act as a secure proxy to the **Google Gemini API**, encapsulating all prompt engineering and protecting sensitive API keys from the client.



---

### 2. Frontend Architecture: Next.js App Router

The frontend is built to be modular and performant, leveraging the latest features of the Next.js App Router.

#### 2.1. Directory Structure

The project follows the standard `app` directory structure, using route groups `(main)` and `(immersive)` to apply different layouts without affecting the URL.

```plaintext
/app
├── (main)                                # Route group for views with the main Navbar
│   ├── layout.tsx                        # Main layout with Navbar
│   ├── page.tsx                          # FEED view (/)
│   └── product
│       └── [id]                          # Dynamic route for a single product
│           ├── page.tsx                  # PRODUCT_DETAILS view (/product/[id])
│           └── stylist
│               └── page.tsx              # STYLIST_CHAT view (/product/[id]/stylist)
│
├── (immersive)                           # Route group for full-screen, no-nav views
│   └── product
│       └── [id]
│           └── try-on
│               └── page.tsx              # AR_TRY_ON view (/product/[id]/try-on)
│
├── api                                   # API Routes (used if deploying on Vercel, otherwise Cloud Functions are preferred)
├── components                            # Reusable UI components
│   ├── ar/ARView.tsx                     # (Client Component)
│   ├── chat/GeminiStylist.tsx            # (Client Component)
│   ├── layout/Navbar.tsx                 # (Client Component)
│   ├── product/ProductCard.tsx           # (Server Component)
│   ├── product/SustainabilityTracker.tsx # (Server Component)
│   └── ui/                               # Generic UI primitives (buttons, sliders)
│
└── lib                                   # Helpers, Firebase config, data fetching
    ├── firebase.ts                       # Firebase client SDK initialization
    └── store.ts                          # Zustand store for global client state
```

#### 2.2. Component & Routing Strategy

The application's "View States" are mapped directly to routes, with a clear distinction between Server and Client Components.

*   **FEED (`/`):** A **Server Component** (`app/(main)/page.tsx`) that fetches product data from Firestore on the server for a fast, SEO-friendly initial load. It renders `<ProductCard>` Server Components.
*   **PRODUCT\_DETAILS (`/product/[id]`):** An `async` **Server Component** that fetches a single product's data. It renders static information server-side (like `<SustainabilityTracker>`) and includes interactive Client Components for features like the AI analysis.
*   **STYLIST\_CHAT (`/product/[id]/stylist`):** A page that hosts the `<GeminiStylist>` **Client Component**. It fetches initial product context on the server to pass as props.
*   **AR\_TRY\_ON (`/product/[id]/try-on`):** Placed in the `(immersive)` route group, this page renders the `<ARView>` **Client Component** without the main `Navbar` for a full-screen experience.

#### 2.3. State Management

A hybrid state management strategy ensures efficiency and simplicity:

1.  **URL as State:** The Next.js router is the primary source of truth for the current view and selected product, making the application's state shareable and resilient.
2.  **Component-Local State (`useState`, `useReducer`):** Used for state that is confined to a single component, such as the AR garment's transformations in `ARView.tsx` or the message history in `GeminiStylist.tsx`.
3.  **Shared Client State (Zustand):** A lightweight library like **Zustand** is used for minimal global state that needs to be shared across client components, such as the user's "Impact Stats" (e.g., CO2 saved), which might be displayed in both the Navbar and the main Feed.

---

### 3. Backend and Data Architecture: Firebase Platform

The backend is entirely serverless, leveraging the Firebase suite for scalability and ease of maintenance.

#### 3.1. Firestore NoSQL Database

Firestore stores all application data in a flexible collection-document model.

*   **`products` Collection:** Contains the entire curated product catalog. Each document represents one product.
    ```typescript
    // /products/{productId}
    interface Product {
      id: string;
      name: string;
      brand: string;
      price: number;
      image: string; // URL to Cloud Storage
      overlayImage: string; // URL to AR overlay in Cloud Storage
      sustainabilityScore: number; // 0-100
      carbonFootprint: string; // "5.2 kg CO2e"
      materials: string[];
      supplyChain: SupplyChainStep[];
    }
    ```

*   **`users` Collection:** Stores user-specific data, keyed by their Firebase Authentication UID.
    ```typescript
    // /users/{userId}
    interface User {
      uid: string; // Firebase Auth UID
      email: string;
      impactStats: { savedCO2: number; };
      wishlist: string[]; // Array of productIds
    }
    ```

*   **`chats` Subcollection:** Nests chat histories under each user, organized by product.
    ```typescript
    // /users/{userId}/chats/{productId}
    interface ChatSession {
      productId: string;
      lastUpdated: Timestamp;
      messages: { role: 'user' | 'model'; content: string; }[];
    }
    ```

#### 3.2. Firestore Security Rules

Rules are defined to protect data, ensuring users can only access their own information while product data remains publicly readable.

```javascript
// firestore.rules
rules_version = '2';
service cloud.firestore {
  match /databases/{database}/documents {
    // Products are public to read, but only admins can write.
    match /products/{productId} {
      allow read: if true;
      allow write: if request.auth.token.admin === true;
    }

    // Users can only read and write their own data.
    match /users/{userId} {
      allow read, update, create: if request.auth.uid == userId;
    }

    // Users can only access their own chat history.
    match /users/{userId}/chats/{chatId} {
      allow read, write: if request.auth.uid == userId;
    }
  }
}
```

#### 3.3. Google Cloud Storage for Assets

Cloud Storage houses all binary files, primarily images.

*   **Folder Structure:** A programmatic structure links assets directly to their Firestore documents.
    *   `products/{productId}/image_1024x1024.jpg`
    *   `products/{productId}/ar_overlay.png`
*   **Security Rules:** Rules allow public read access for all product assets but restrict write access to authenticated administrators.
*   **Optimization:**
    *   **Automated Resizing:** A Cloud Function is triggered on image upload to automatically create optimized thumbnails (e.g., 400x400) for faster loading in the feed view.
    *   **Global CDN:** Assets are automatically served via Google's global CDN for low-latency delivery worldwide.

---

### 4. Core Feature Implementation Details

#### 4.1. Augmented Reality (AR) Virtual Try-On

The AR feature is implemented using web-native technologies for maximum compatibility and performance, avoiding the overhead of heavy 3D libraries.

*   **Recommended Technology:** **HTML5 `getUserMedia` API + Canvas API**. This lightweight stack is perfectly suited for overlaying a 2D transparent PNG onto a live camera feed. It provides direct control over rendering and gestures without unnecessary complexity.
*   **`ARView.tsx` Component Architecture:**
    *   **Camera Access:** A `useEffect` hook manages the camera lifecycle, requesting the rear-facing (`environment`) camera stream via `getUserMedia` on mount and releasing it on unmount.
    *   **Canvas Rendering:** A `<canvas>` element is absolutely positioned over the `<video>` feed. A render function redraws the `overlayImage` on the canvas whenever the garment's transformation state changes, using canvas context methods (`translate`, `rotate`, `scale`).
    *   **State Management:** Local `useState` hook manages the garment's transformation object: `{ x, y, scale, rotation }`.
    *   **Gesture Handling:** Touch event listeners (`onTouchStart`, `onTouchMove`) on a container div detect single-finger drags (for movement or rotation based on a selected mode) and two-finger gestures (for intuitive rotation). A standard HTML `<input type="range">` slider controls scaling.

#### 4.2. AI-Powered Services (Gemini & Cloud Functions)

The AI features are implemented as two distinct serverless microservices to ensure security and separation of concerns. The Next.js frontend never directly interacts with the Gemini API.

*   **Service 1: EcoBot Stylist (`generateStylingAdvice`)**
    *   **Trigger:** An HTTP-triggered Cloud Function (`POST`).
    *   **Logic:** Receives the product context and entire chat history from the client. It prepends a system instruction to establish the "EcoBot" persona: *"You are EcoBot, an expert sustainable fashion stylist..."*.
    *   **Model:** `gemini-2.5-flash`, configured for a real-time chat experience.
    *   **API Contract:**
        *   **Request:** `POST { productContext, chatHistory }`
        *   **Response:** `200 OK { reply: "..." }`

*   **Service 2: Automated Sustainability Analysis (`analyzeSustainability`)**
    *   **Trigger:** An HTTP-triggered Cloud Function (`POST`).
    *   **Logic:** Receives key product attributes (name, materials, score). It constructs a specific, one-shot prompt to generate a brief, encouraging analysis: *"As a sustainability expert... write a brief 'Eco-Analysis'..."*.
    *   **Model:** `gemini-2.5-flash`, with a lower temperature (`0.4`) for more consistent, factual outputs.
    *   **API Contract:**
        *   **Request:** `POST { productName, materials, sustainabilityScore }`
        *   **Response:** `200 OK { analysis: "..." }`

*   **Security & Best Practices:**
    *   The Gemini API key is stored securely as an environment variable in the Cloud Function settings.
    *   IAM roles (`roles/cloudfunctions.invoker`) are used to ensure only the authenticated application can invoke these functions.
    *   Results from the `analyzeSustainability` function can be cached in the product's Firestore document to reduce costs and latency on subsequent views.

**Metadata:**
```json
{
  "subtask_count": 4
}
```
